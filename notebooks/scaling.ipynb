{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebook_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import emcee\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "\n",
    "import exoplanet as xo\n",
    "\n",
    "target_n_eff = 500\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "N_pl = 1\n",
    "periods = np.exp(np.random.uniform(np.log(1), np.log(100), size=N_pl))\n",
    "t0s = periods * np.random.rand(N_pl)\n",
    "Ks = np.sort(np.exp(np.random.uniform(np.log(2), np.log(10), N_pl)))[::-1]\n",
    "eccs = np.random.uniform(0, 0.1, N_pl)\n",
    "omegas = np.random.uniform(-np.pi, np.pi, N_pl)\n",
    "\n",
    "N = 25 + 25 * N_pl\n",
    "x = np.sort(np.random.uniform(-2*365, 2*365, N))\n",
    "yerr = np.random.uniform(0.5, 5.0, N)\n",
    "\n",
    "t = np.linspace(x.min()-5, x.max()+5, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "\n",
    "    # Gaussian priors based on transit data (from Petigura et al.)\n",
    "    t0 = pm.Normal(\"t0\", mu=np.array(t0s), sd=10.0, shape=N_pl)\n",
    "    logP = pm.Normal(\"logP\", mu=np.log(periods), sd=1.0, shape=N_pl)\n",
    "    P = pm.Deterministic(\"P\", tt.exp(logP))\n",
    "\n",
    "    # Wide log-normal prior for semi-amplitude\n",
    "    logK = pm.Normal(\"logK\", mu=np.log(Ks), sd=10.0, shape=N_pl)\n",
    "\n",
    "    # This is a sanity check that restricts the semiamplitude to reasonable\n",
    "    # values because things can get ugly as K -> 0\n",
    "    pm.Potential(\"logK_bound\", tt.switch(logK < -2., -np.inf, 0.0))\n",
    "    \n",
    "    # The amlitudes should be sorted\n",
    "    pm.Potential(\"logK_order\", tt.switch(logK[1:] > logK[:-1], -np.inf, 0.0))\n",
    "\n",
    "    # We also want to keep period physical but this probably won't be hit\n",
    "    pm.Potential(\"P_bound\", tt.switch(P <= 0, -np.inf, 0.0))\n",
    "\n",
    "    # Eccentricity & argument of periasteron\n",
    "    ecc = pm.Uniform(\"ecc\", lower=0, upper=0.99, shape=N_pl,\n",
    "                     testval=eccs)\n",
    "    omega = xo.distributions.Angle(\"omega\", shape=N_pl, testval=omegas)\n",
    "\n",
    "    # Jitter & a quadratic RV trend\n",
    "    logs = pm.Normal(\"logs\", mu=np.log(np.median(yerr)), sd=5.0)\n",
    "    trend = pm.Normal(\"trend\", mu=0, sd=10.0**-np.arange(3)[::-1], shape=3)\n",
    "    \n",
    "    # Set up the orbit\n",
    "    orbit = xo.orbits.KeplerianOrbit(\n",
    "        period=P, t0=t0,\n",
    "        ecc=ecc, omega=omega)\n",
    "\n",
    "    # Set up the RV model and save it as a deterministic\n",
    "    # for plotting purposes later\n",
    "    vrad = orbit.get_radial_velocity(x, K=tt.exp(logK))\n",
    "    if N_pl == 1:\n",
    "        vrad = vrad[:, None]\n",
    "    pm.Deterministic(\"vrad\", vrad)\n",
    "\n",
    "    # Define the background model\n",
    "    A = np.vander(x - 0.5*(x.min() + x.max()), 3)\n",
    "    bkg = pm.Deterministic(\"bkg\", tt.dot(A, trend))\n",
    "\n",
    "    # Sum over planets and add the background to get the full model\n",
    "    rv_model = pm.Deterministic(\"rv_model\", tt.sum(vrad, axis=-1) + bkg)\n",
    "\n",
    "    # Simulate the data\n",
    "    y_true = xo.eval_in_model(rv_model)\n",
    "    y = y_true + yerr * np.random.randn(len(yerr))\n",
    "    \n",
    "    # Compute the prediction\n",
    "    vrad_pred = orbit.get_radial_velocity(t, K=tt.exp(logK))\n",
    "    if N_pl == 1:\n",
    "        vrad_pred = vrad_pred[:, None]\n",
    "    pm.Deterministic(\"vrad_pred\", vrad_pred)\n",
    "    A_pred = np.vander(t - 0.5*(x.min() + x.max()), 3)\n",
    "    bkg_pred = pm.Deterministic(\"bkg_pred\", tt.dot(A_pred, trend))\n",
    "    rv_model_pred = pm.Deterministic(\"rv_model_pred\", tt.sum(vrad_pred, axis=-1) + bkg_pred)\n",
    "    \n",
    "    # Likelihood\n",
    "    err = tt.sqrt(yerr**2 + tt.exp(2*logs))\n",
    "    pm.Normal(\"obs\", mu=rv_model, sd=err, observed=y)\n",
    "\n",
    "    # Optimize\n",
    "    map_soln = pm.find_MAP(start=model.test_point, vars=[trend])\n",
    "    map_soln = pm.find_MAP(start=map_soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x, y, yerr=yerr, fmt=\".k\")\n",
    "plt.plot(t, map_soln[\"vrad_pred\"], \"--k\", alpha=0.5)\n",
    "plt.plot(t, map_soln[\"rv_model_pred\"], label=\"model\")\n",
    "plt.plot(t, map_soln[\"bkg_pred\"], \":k\", alpha=0.5)\n",
    "\n",
    "plt.legend(fontsize=10)\n",
    "plt.xlim(t.min(), t.max())\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.ylabel(\"radial velocity [m/s]\")\n",
    "plt.title(\"MAP model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_convergence(samples):\n",
    "    tau = emcee.autocorr.integrated_time(samples, tol=0)\n",
    "    num = samples.shape[0] * samples.shape[1]\n",
    "    print(num / tau)\n",
    "    converged = np.all(tau * target_n_eff < num)\n",
    "    converged &= np.all(len(samples) > 50 * tau)\n",
    "    return converged, num / tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = xo.PyMC3Sampler(finish=200, window=200)\n",
    "with model:\n",
    "    burnin = sampler.tune(tune=5000, start=map_soln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = 2\n",
    "tottime = 0\n",
    "trace = None\n",
    "with model:\n",
    "    while True:\n",
    "        strt = time.time()\n",
    "        trace = sampler.sample(draws=2000, trace=trace, chains=chains, cores=1)\n",
    "        tottime += time.time() - strt\n",
    "        \n",
    "        samples = np.array(trace.get_values(\"P\", combine=False))\n",
    "        samples = np.moveaxis(samples, 0, 1)\n",
    "        flag, n_eff = check_convergence(samples)\n",
    "        if flag:\n",
    "            break\n",
    "\n",
    "    time_pymc = tottime\n",
    "    time_ind_pymc = tottime / n_eff\n",
    "    n_eff_pymc = n_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_ind_pymc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "for n, letter in enumerate(string.ascii_lowercase[1:N_pl+1]):\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # Get the posterior median orbital parameters\n",
    "    p = np.median(trace[\"P\"][:, n])\n",
    "    t0 = np.median(trace[\"t0\"][:, n])\n",
    "\n",
    "    # Compute the median of posterior estimate of the background RV\n",
    "    # and the contribution from the other planet. Then we can remove\n",
    "    # this from the data to plot just the planet we care about.\n",
    "    if N_pl > 1:\n",
    "        inds = np.arange(N_pl) != n\n",
    "        other = np.median(np.sum(trace[\"vrad\"][:, :, inds], axis=-1), axis=0)\n",
    "    else:\n",
    "        other = np.zeros_like(y)\n",
    "    other += np.median(trace[\"bkg\"], axis=0)\n",
    "\n",
    "    # Plot the folded data\n",
    "    x_fold = (x - t0 + 0.5*p) % p - 0.5*p\n",
    "    plt.errorbar(x_fold, y - other, yerr=yerr, fmt=\".k\")\n",
    "\n",
    "    # Compute the posterior prediction for the folded RV model for this\n",
    "    # planet\n",
    "    t_fold = (t - t0 + 0.5*p) % p - 0.5*p\n",
    "    inds = np.argsort(t_fold)\n",
    "    pred = np.percentile(trace[\"vrad_pred\"][:, inds, n], [16, 50, 84], axis=0)\n",
    "    plt.plot(t_fold[inds], pred[1], color=\"C0\", label=\"model\")\n",
    "    art = plt.fill_between(t_fold[inds], pred[0], pred[2], color=\"C0\", alpha=0.3)\n",
    "    art.set_edgecolor(\"none\")\n",
    "    \n",
    "    plt.annotate(\"period = {0:.4f} +/- {1:.4f} d\".format(p, np.std(trace[\"P\"][:, n])),\n",
    "                 (0, 1), xycoords=\"axes fraction\",\n",
    "                 xytext=(5, -5), textcoords=\"offset points\",\n",
    "                 va=\"top\", ha=\"left\", fontsize=12)\n",
    "\n",
    "    plt.annotate(\"true period = {0:.4f} d\".format(periods[n]),\n",
    "                 (0, 0), xycoords=\"axes fraction\",\n",
    "                 xytext=(5, 5), textcoords=\"offset points\",\n",
    "                 va=\"bottom\", ha=\"left\", fontsize=12)\n",
    "    \n",
    "    plt.legend(fontsize=10)\n",
    "    plt.xlim(-0.5*p, 0.5*p)\n",
    "    plt.xlabel(\"phase [days]\")\n",
    "    plt.ylabel(\"radial velocity [m/s]\")\n",
    "    \n",
    "    fig.savefig(\"phase-{0}.pdf\".format(letter))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit using emcee\n",
    "with model:\n",
    "    # Loop over samples and convert to the relevant parameter space;\n",
    "    # I'm sure that there's an easier way to do this, but I don't know\n",
    "    # how to make something work in general...\n",
    "    N = len(trace) * trace.nchains\n",
    "    samples = np.empty((N, model.ndim))\n",
    "    i = 0\n",
    "    for chain in trace._straces.values():\n",
    "        for p in chain:\n",
    "            samples[i] = model.bijection.map(p)\n",
    "            i += 1\n",
    "    \n",
    "    # Build a wrapper around the theano model\n",
    "    f = theano.function(model.vars,\n",
    "                        [model.logpt] + model.vars + model.deterministics)\n",
    "\n",
    "    def log_prob_func(params):\n",
    "        dct = model.bijection.rmap(params)\n",
    "        args = (dct[k.name] for k in model.vars)\n",
    "        results = f(*args)\n",
    "        return tuple(results)\n",
    "\n",
    "    # First we work out the shapes of all of the deterministic variables\n",
    "    res = model.test_point\n",
    "    vec = model.bijection.map(res)\n",
    "    initial_blobs = log_prob_func(vec)[1:]\n",
    "    dtype = [(var.name, float, np.shape(b)) for var, b in\n",
    "             zip(model.vars + model.deterministics, initial_blobs)]\n",
    "\n",
    "    # Then sample as usual\n",
    "    coords = samples[np.random.randint(len(samples), size=2*samples.shape[1])]  # vec + 1e-5 * np.random.randn(3*len(vec), len(vec))\n",
    "    nwalkers, ndim = coords.shape\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob_func,\n",
    "                                    blobs_dtype=dtype)\n",
    "    thin_by = 10\n",
    "    tottime = 0\n",
    "    for i in range(1000):\n",
    "        strt = time.time()\n",
    "        sampler.run_mcmc(coords, 500, thin_by=thin_by, progress=True)\n",
    "        tottime += time.time() - strt\n",
    "\n",
    "        samples = sampler.get_blobs()[\"P\"]\n",
    "        flag, n_eff = check_convergence(samples)\n",
    "        if flag:\n",
    "            break\n",
    "    \n",
    "    time_emcee = tottime\n",
    "    time_ind_emcee = tottime / n_eff\n",
    "    n_eff_emcee = n_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pm.trace_to_dataframe(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = sampler.get_blobs(flat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File(\"blah.h5\", \"w\") as f:\n",
    "    f.create_dataset(\"blobs\", data=blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame.from_records(blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
